ISLR - Google Search
Book: An introduction to statistical learning

** What is Machine Learning ?
There are 3 main types of ML algorithms
-Supervised learning
-Unsupervised learning
-Reinforcement leaarning

** Supervised Learning
We have labelled data and are trying to group together predict a label based off of known features

** Unsupervised Learning
We have unlabelled data and are trying to group together similar data points based off of features

** Reinforcement Learning
Algorithms learns to perform an action from experience

** Supervised Learning **
- Supervised learning algorithms are trained using labelled examples, suchc as an input where the desired output is known
- for example, apiece of equipment ould have data points labelled either 'F' (failed) or 'R' (runs)
- The learnig algorithm receives a set of inputs along with the corresponding correct outputs and the algorithm learns by comparing its actual output with correct outputs to find errors
- It then modifies the model accordingly
- Through methods like classification, regression,prediction and gradient boosting, supervised learning uses patterns to predict the values of the label on additional unlabelled data
- Supervised  learning is commonly used in appications where historical data predicts likely future events
- For example. it can anticipate when credit card transactions are likely to be fraudulent or which insurance customer is likely to file a claim
- Or it can attempt to predict the price of a house based on differnet features for which we have historical price data


** Unsupervised Learning **
- Unsupervised learning is used against data that has no historical leabels
- The system is not told the 'right answer'. The algorithm must figure out what is being shown
- The goal is to explore the data and find some structure within
- Or it can find the main attributes that separate customer segments from each other
- Popular techniques include self-organizing maps, nearest-neighbour mapping, K-means clustering and single value decomposition
- These algorithms are used to segment text topics, recommend items and identify data outliers


** Reinforcement Learning **
- Reinforcement leanring is often used for robotics, gaming and navigation
- With reinforcement learning, the algrithm discovers through trial and error which actions yield the greatest rewards
- this type of learning has three primary components:
	the agent(the learner or decision maker)
	the environment(everything the agent interacts with)
	actions(what agent can do)
- The obejctive is for the agent to choose actions that maximizes the expected reward over a given amount of time
- The agent will reach the goal much faster by following a good policy
- So the goal in reinforcemnt learning is to learn the best policy



##  Scikit-Learn Package ##

For installation
	conda install scikit-learn
		or
	pip install scikit-learn

- Every algorithm is exposed in scikit-learn via an 'Estimator'
- general form of installation is....
	from sklearn.family import Model
- for example
	from sklearn.linear_model import LinearRegression

** Estimator Parameters **

- All the parameters of an estimator can be set when it is instantiated and have suitable default values
- for example
	model = LinearRegression(normalize = True)
	print(model)

	LinearRegression(copy_X = True, fit_intercept = True, normalize = True)
- Once w have your model created with our parameters it is the time to fit our model on some data
- But remember, we should split this data into a training set and test set

- We can train/fit our model on the training data through the model.fit() method:
	model.fit(X_train, y_train )
- Now the model has been fit and trained on the training data
- The model is ready to predict labels or values on the test set
- We get the predicted values using the predict method:
	predictions = model.predict(X_test)
- We can then evaluate our model by comparing our predictions to the correct values
- The evaluation method depends on what sort of ML algorithm we are using(eg. Regression, classification, clustering etc.)



- Scikit-learn strives to have a uniform interface across all the methods
- Given a scikit-learn eastimator object named model, the following methods are available:
	- model.fit() : fit the training data
	> For supervised learning applications, this accepts two arguments: the data X and the labels y(eg. model.fit(X,y))
	> For unsupervised learning applications, this accepts only a single argument, the data X (eg. model.fit(X))

~ Available in ** Supervised estimators **
	> model.predict(): given a trained model, predict the label of new set of data. This method accepts one argument, the new data X_new (eg. model.predict(X_new)), and returns the label for each object in the array
	> model.predict_proba(): For classification problems, some estimators also provide this method, which returns the probability that a new observation has each categorical label. In this case, the label with the highest probability is returbed by model.predict()
	> model.score(): For regression or classification problems, most estimators implement a score method. Scores are between 0 and 1, with a larger score indicating a better fit.
	> model.predict(): predict labels in clustering algorithms

~ Available in ** Unsupervised estimators **
	> model.transform(): given an unsupervised model, transform new data into the new basis. This also accepts one argument X_new and returns the new representation of the data ased on the unsupevised model
	> model.fit_transform(): some estimators implement this method, which more efficiently performs a fit and a transform on the same input data





  